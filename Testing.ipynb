{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __`POKE-ENV` RL MAIN NOTEBOOK__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an easy way to connect with the `pokemon-showdown-master` module. It will implement an RL approach to Pokemon battling on a local Pokemon Showdown server.\n",
    "\n",
    "> note: A Local Pokemon-Showdown server is required to run this code. for more details look [here](https://github.com/smogon/pokemon-showdown/blob/master/server/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the neccassary imports that are needed for the notebook to function as intended. \n",
    "use `pip install poke-env` to install poke-env\n",
    "\n",
    "`Create_teams.py` should be included in the repository and can be found [here](https://github.com/TrevorKWalker/Poke-AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are the neccassary imports that are needed for the notebook to function as intended. \n",
    "from poke_env.player.player import Player\n",
    "from poke_env import RandomPlayer\n",
    "from poke_env.ps_client.server_configuration import ServerConfiguration\n",
    "from poke_env import AccountConfiguration\n",
    "import asyncio\n",
    "import nest_asyncio \n",
    "import Create_teams\n",
    "import simple_rl_player\n",
    "\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Box, Space\n",
    "from poke_env.data import GenData\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from poke_env.environment.abstract_battle import AbstractBattle\n",
    "from poke_env.player.player import Player\n",
    "from poke_env.player.openai_api import OpenAIGymEnv\n",
    "from poke_env.player.env_player import Gen8EnvSinglePlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Constants\n",
    "These are globals that mainly relate to the server you are hosting, Check to ensure that they are correct for your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of the account for the Bot that you use. Should only neccassary for challenging Human players. \n",
    "my_account_config = AccountConfiguration(\"175bot\", \"pokeai\")\n",
    "\n",
    "# The address of the server that you are hosting. \n",
    "server_config = ServerConfiguration(\n",
    "        websocket_url=\"ws://localhost:8000/showdown/websocket\",  # WebSocket URL for your local server\n",
    "        authentication_url=\"http://localhost:8000\",           # Authentication URL (often the same as server URL)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a player for a gen 9 random battle\n",
    "\n",
    "we must make 2 players and then we can have them battle against each other. we will create Random players from poke-env. \n",
    "battle_against allows us to have one bot send another bot a challenge and battle. it takes parameters : `oppenent : str` and `n_batttles` : `int`\n",
    "by using RandomPlayer having these two battle will cause a gen 9 random battle ( at the time of writing)\n",
    "\n",
    "If the code runs the outcome will be visable on the local server that is being hosted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_1 = RandomPlayer()\n",
    "player_2 = RandomPlayer()\n",
    "await player_1.battle_against(player_2, n_battles=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating teams using `Create_teams.py`\n",
    "`create_teams` takes one parameter: `directory` which is the path to the folder containing the teams as seperate .txt files. Each team is in a seperate .txt file in pokemon showdown export format.\n",
    "Easiest way to make new teams is to use [pokemon showdown](https://play.pokemonshowdown.com/teambuilder) to create a team and then export it as text. \n",
    "The pokemon must be in the Pokemon Showdown format or the server will stall later due to the team getting rejected by the validater.\n",
    "Depending on the teams that you make you may need to change the `battle_format` in the future sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#competitive teams that are taken from past top placing teams in format H\n",
    "Competitive_teams = Create_teams.create_teams(\"./Teams/Competitive\")\n",
    "Num_competitive_teams = len(Competitive_teams)\n",
    "\n",
    "\n",
    "# Teams of pokemon that are set to lvl 50. All teams of 3 from different generations with movesets they would have at lvl 15 (lvl 15 was chosen because that is the average lvl cap of the first gym in nuzlockes.)\n",
    "Early_game_teams = Create_teams.create_teams(\"./Teams/In-Game/Early_game\")\n",
    "Num_early_game_teams = len(Early_game_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Custom Player Class\n",
    "\n",
    " To start we will use `MaxDamagePlayer` which is a simple player that always chooses the highest base power move. This is the most basic that is possible and only being used to better understand the Poke-env module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaxDamagePlayer(Player):\n",
    "    def choose_move(self, battle):\n",
    "        # Choose the move with the highest base power\n",
    "        if battle.available_moves:\n",
    "            best_move = max(battle.available_moves, key=lambda move: move.base_power)\n",
    "\n",
    "            # Terastallize if possible\n",
    "            if battle.can_tera:\n",
    "                return self.create_order(best_move, terastallize=True)\n",
    "\n",
    "            return self.create_order(best_move)\n",
    "        else:\n",
    "            return self.choose_random_move(battle)\n",
    "    def choose_team_preview(self, battle):\n",
    "        \n",
    "        # For simplicity, send the first Pok√©mon in the team\n",
    "        return \"/team 1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a player for `MaxDamagePlayer`\n",
    "\n",
    "To be able to create a player that uses `MaxDamagePlayer` and is able to battle with one of our teams we must assign it a battle format that is not random battles. availible battle formats are found in `config/formats.ts`\n",
    "All `competitive` teams are able to be played in Gen9 OU but because `In-Game` teams need Gen9balancedhackmons we will be using that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create player_1 with the right battle_format and  give them a team\n",
    "player_1 = MaxDamagePlayer(battle_format=\"gen9balancedhackmons\", team = Early_game_teams[0])\n",
    "\n",
    "\n",
    "#create player_2 with the right battle_format and  give them a team\n",
    "player_2 = MaxDamagePlayer( battle_format=\"gen9balancedhackmons\", team = Early_game_teams[1])\n",
    "\n",
    "\n",
    "# Have them battle. check the local server to see results\n",
    "await player_1.battle_against(player_2, n_battles=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenging the Human\n",
    "\n",
    "This section will cover how to send a challenge to a Human player. The Human must also be on an account that is connected to the local server. we will use send_challenges which is similar to battle against but for Humans. \n",
    "\n",
    "IMPORTANT: The human is required to have a team that is the same size as the agent of the game will hang indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the agent in the same way\n",
    "player_1 = MaxDamagePlayer(battle_format=\"gen9balancedhackmons\", team = Early_game_teams[0])\n",
    "\n",
    "\n",
    "# change oppenent to your pokemon showdown account name.\n",
    "await player_1.send_challenges(opponent=\"KingKylan\", n_challenges=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing RL policies\n",
    "first we need to make a new custom player class as before that will be our RL agent. this is defined in simple_rl_player.py\n",
    "\n",
    "next we need an oppenent so that we can test the env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = \"\"\"Porygon2 @ Eviolite  \n",
    "Ability: Download  \n",
    "Level: 50  \n",
    "Tera Type: Ground  \n",
    "EVs: 252 HP / 4 Atk / 100 Def / 116 SpA / 36 SpD  \n",
    "Quiet Nature  \n",
    "- Tera Blast  \n",
    "- Ice Beam  \n",
    "- Recover  \n",
    "- Trick Room  \n",
    "\n",
    "Sneasler @ Focus Sash  \n",
    "Ability: Poison Touch  \n",
    "Level: 50  \n",
    "Tera Type: Flying  \n",
    "EVs: 252 Atk / 4 SpD / 252 Spe  \n",
    "Jolly Nature  \n",
    "- Close Combat \n",
    "- Coaching  \n",
    "- Protect  \n",
    "\n",
    "Gholdengo @ Life Orb  \n",
    "Ability: Good as Gold  \n",
    "Level: 50  \n",
    "Tera Type: Water  \n",
    "EVs: 212 HP / 148 Def / 132 SpA / 12 SpD  \n",
    "Modest Nature  \n",
    "IVs: 0 Atk  \n",
    "- Make It Rain  \n",
    "- Shadow Ball  \n",
    "- Nasty Plot  \n",
    "- Protect  \n",
    "\n",
    "Talonflame @ Sharp Beak  \n",
    "Ability: Gale Wings  \n",
    "Level: 50  \n",
    "Tera Type: Ghost  \n",
    "EVs: 4 HP / 252 Atk / 252 Spe  \n",
    "Jolly Nature  \n",
    "- Dual Wingbeat  \n",
    "- Tailwind  \n",
    "- Will-O-Wisp  \n",
    "- Protect  \n",
    "\n",
    "Garchomp @ Clear Amulet  \n",
    "Ability: Rough Skin  \n",
    "Level: 50  \n",
    "Tera Type: Fire  \n",
    "EVs: 44 HP / 204 Atk / 4 Def / 4 SpD / 252 Spe  \n",
    "Jolly Nature  \n",
    "- Earthquake  \n",
    "- Stomping Tantrum  \n",
    "- Dragon Claw  \n",
    "- Protect  \n",
    "\n",
    "Incineroar @ Safety Goggles  \n",
    "Ability: Intimidate  \n",
    "Level: 50  \n",
    "Tera Type: Ghost  \n",
    "EVs: 252 HP / 36 Atk / 76 Def / 140 SpD  \n",
    "Brave Nature  \n",
    "IVs: 29 Spe  \n",
    "- Flare Blitz  \n",
    "- Knock Off  \n",
    "- Fake Out  \n",
    "- Parting Shot  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -30      |\n",
      "| time/              |          |\n",
      "|    fps             | 221      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039827824 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | -0.0146     |\n",
      "|    learning_rate        | 0.01        |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.0185      |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.2      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 242       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 22.664843 |\n",
      "|    clip_fraction        | 0.947     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.528    |\n",
      "|    explained_variance   | 0.741     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 3.59      |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | 0.581     |\n",
      "|    value_loss           | 4.98      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.4      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 245       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.72e-06 |\n",
      "|    explained_variance   | 0.237     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.854     |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | 1.22e-11  |\n",
      "|    value_loss           | 16.6      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.3      |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 245       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.7e-06  |\n",
      "|    explained_variance   | 0.183     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.634     |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -2.79e-10 |\n",
      "|    value_loss           | 15.9      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.3      |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.73e-06 |\n",
      "|    explained_variance   | 0.212     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.433     |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | 2.41e-10  |\n",
      "|    value_loss           | 15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31        |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 249       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.73e-06 |\n",
      "|    explained_variance   | 0.152     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.699     |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | 7.97e-10  |\n",
      "|    value_loss           | 16.2      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.8      |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.8e-06  |\n",
      "|    explained_variance   | 0.214     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 30.2      |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -1.11e-09 |\n",
      "|    value_loss           | 15.2      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.78e-06 |\n",
      "|    explained_variance   | 0.207     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 1.3       |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | 3.12e-10  |\n",
      "|    value_loss           | 16.3      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31        |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.9e-06  |\n",
      "|    explained_variance   | 0.698     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.648     |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -5.92e-10 |\n",
      "|    value_loss           | 1.37      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 32.3      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.86e-06 |\n",
      "|    explained_variance   | 0.185     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 5.9       |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | 1.4e-10   |\n",
      "|    value_loss           | 15.2      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.4      |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.93e-06 |\n",
      "|    explained_variance   | 0.253     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 81.5      |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -1.07e-10 |\n",
      "|    value_loss           | 16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.2      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.17e-06 |\n",
      "|    explained_variance   | 0.225     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.682     |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -6.85e-10 |\n",
      "|    value_loss           | 15.7      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.8      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 249       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.19e-06 |\n",
      "|    explained_variance   | 0.801     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.582     |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -2.05e-10 |\n",
      "|    value_loss           | 1.14      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.5      |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 122       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.39e-06 |\n",
      "|    explained_variance   | 0.245     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.361     |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -1.34e-09 |\n",
      "|    value_loss           | 12.5      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.2      |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 130       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.28e-06 |\n",
      "|    explained_variance   | 0.843     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.307     |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | 9.43e-09  |\n",
      "|    value_loss           | 0.867     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.7      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.07e-06 |\n",
      "|    explained_variance   | 0.865     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.192     |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | 1.86e-08  |\n",
      "|    value_loss           | 0.692     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 32.2      |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 249       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 147       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.79e-06 |\n",
      "|    explained_variance   | 0.486     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 13.6      |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -1.44e-08 |\n",
      "|    value_loss           | 4.47      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 31.8     |\n",
      "|    ep_rew_mean          | -29.4    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 250      |\n",
      "|    iterations           | 19       |\n",
      "|    time_elapsed         | 155      |\n",
      "|    total_timesteps      | 38912    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -2.6e-05 |\n",
      "|    explained_variance   | 0.285    |\n",
      "|    learning_rate        | 0.01     |\n",
      "|    loss                 | 0.524    |\n",
      "|    n_updates            | 180      |\n",
      "|    policy_gradient_loss | 4.89e-08 |\n",
      "|    value_loss           | 13.2     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.7      |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 163       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0.000146  |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000262 |\n",
      "|    explained_variance   | 0.797     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.445     |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | 3.29e-05  |\n",
      "|    value_loss           | 1.07      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 30.7     |\n",
      "|    ep_rew_mean          | -28.8    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 251      |\n",
      "|    iterations           | 21       |\n",
      "|    time_elapsed         | 171      |\n",
      "|    total_timesteps      | 43008    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.4e-12 |\n",
      "|    explained_variance   | 0.846    |\n",
      "|    learning_rate        | 0.01     |\n",
      "|    loss                 | 0.52     |\n",
      "|    n_updates            | 200      |\n",
      "|    policy_gradient_loss | 4.43e-10 |\n",
      "|    value_loss           | 0.874    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.1      |\n",
      "|    ep_rew_mean          | -27.6     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 179       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.36e-12 |\n",
      "|    explained_variance   | 0.157     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 22.9      |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -7.82e-12 |\n",
      "|    value_loss           | 17.1      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.6      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 249       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 188       |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.36e-12 |\n",
      "|    explained_variance   | 0.137     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 17.1      |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -5.3e-10  |\n",
      "|    value_loss           | 37.3      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 32        |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 196       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.37e-12 |\n",
      "|    explained_variance   | -0.171    |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.973     |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -1.65e-10 |\n",
      "|    value_loss           | 2.63      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 32.2      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 204       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.41e-12 |\n",
      "|    explained_variance   | 0.173     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 39.6      |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | 6.33e-10  |\n",
      "|    value_loss           | 27.2      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.2      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 212       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.37e-12 |\n",
      "|    explained_variance   | 0.754     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.826     |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -1.62e-09 |\n",
      "|    value_loss           | 1.37      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.6      |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 220       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.36e-12 |\n",
      "|    explained_variance   | 0.201     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.495     |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -1.27e-09 |\n",
      "|    value_loss           | 16.4      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31        |\n",
      "|    ep_rew_mean          | -28.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 227       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.35e-12 |\n",
      "|    explained_variance   | 0.187     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.499     |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | 5.71e-10  |\n",
      "|    value_loss           | 15.6      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 32.1      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 235       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.36e-12 |\n",
      "|    explained_variance   | -0.0124   |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 3.51      |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | 1.57e-09  |\n",
      "|    value_loss           | 35.8      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 32.1      |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 245       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.42e-12 |\n",
      "|    explained_variance   | 0.513     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.682     |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -1.83e-10 |\n",
      "|    value_loss           | 1.11      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.5      |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 253       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.37e-12 |\n",
      "|    explained_variance   | 0.82      |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.459     |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -1.83e-09 |\n",
      "|    value_loss           | 0.96      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.2      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 261       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.36e-12 |\n",
      "|    explained_variance   | 0.854     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.284     |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -4.29e-10 |\n",
      "|    value_loss           | 0.845     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 269       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.39e-12 |\n",
      "|    explained_variance   | 0.455     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 5.86      |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | 6.39e-10  |\n",
      "|    value_loss           | 4.85      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.4      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 280       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.35e-12 |\n",
      "|    explained_variance   | 0.859     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.337     |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -8.99e-10 |\n",
      "|    value_loss           | 0.68      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.7      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 288       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.36e-12 |\n",
      "|    explained_variance   | 0.201     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.367     |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | 1.56e-09  |\n",
      "|    value_loss           | 12.9      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.7      |\n",
      "|    ep_rew_mean          | -30       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 297       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.37e-12 |\n",
      "|    explained_variance   | 0.793     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.361     |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -6.87e-10 |\n",
      "|    value_loss           | 0.951     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.4      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 306       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.37e-12 |\n",
      "|    explained_variance   | 0.841     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.463     |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | 9.22e-10  |\n",
      "|    value_loss           | 1.03      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.6      |\n",
      "|    ep_rew_mean          | -28.8     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 245       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 316       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.38e-12 |\n",
      "|    explained_variance   | 0.185     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 2.04      |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | 8.48e-11  |\n",
      "|    value_loss           | 15.8      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.1      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 245       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 325       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.38e-12 |\n",
      "|    explained_variance   | 0.191     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 0.677     |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | 3.52e-10  |\n",
      "|    value_loss           | 16.3      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.1      |\n",
      "|    ep_rew_mean          | -29.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 245       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 334       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.35e-12 |\n",
      "|    explained_variance   | 0.203     |\n",
      "|    learning_rate        | 0.01      |\n",
      "|    loss                 | 5.18      |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | 5.95e-10  |\n",
      "|    value_loss           | 15        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m stable_baselines3\u001b[38;5;241m.\u001b[39mPPO(\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     env,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     ent_coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m CheckpointCallback(save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;124m\"\u001b[39m, name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoke_ppo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoke_ppo_final\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\poke_env\\player\\openai_api.py:366\u001b[0m, in \u001b[0;36mOpenAIGymEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_battle \u001b[38;5;241m=\u001b[39m battle\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actions\u001b[38;5;241m.\u001b[39mput(action)\n\u001b[1;32m--> 366\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_observations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_reward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_battle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_battle)\n\u001b[0;32m    368\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\site-packages\\poke_env\\player\\openai_api.py:39\u001b[0m, in \u001b[0;36m_AsyncQueue.get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     38\u001b[0m     res \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mget(), POKE_LOOP)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Trevor\\miniconda3\\envs\\cs178\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "player_1 = MaxDamagePlayer(battle_format=\"gen9balancedhackmons\", team = team)\n",
    "\n",
    "env = simple_rl_player.SimpleRLPlayer(\n",
    "        battle_format=\"gen9balancedhackmons\", start_challenging=True, opponent=player_1, team = team\n",
    "    )\n",
    "\n",
    "# Define Stable-Baselines3 model\n",
    "model = stable_baselines3.PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=32,\n",
    "    n_epochs=10,\n",
    "    ent_coef=0.01\n",
    ")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path=\"./models/\", name_prefix=\"poke_ppo\")\n",
    "model.learn(total_timesteps=10000, callback=checkpoint_callback)\n",
    "\n",
    "# Save the final model\n",
    "model.save(\"poke_ppo_final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
